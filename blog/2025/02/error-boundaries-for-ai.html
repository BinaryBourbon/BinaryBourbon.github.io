<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Error Boundaries for AI: What React Taught Me About LLM Failures | BinaryBourbon</title>
    <meta name="description" content="How to build resilient AI systems that gracefully handle failures. Practical patterns from production deployments handling 10M+ requests.">
    <meta name="keywords" content="AI error handling, LLM failures, production ML, resilient systems, error boundaries">
    <meta name="author" content="Benjamin Bourbon">
    
    <!-- Open Graph -->
    <meta property="og:title" content="Error Boundaries for AI: What React Taught Me About LLM Failures">
    <meta property="og:description" content="How to build resilient AI systems that gracefully handle failures. Practical patterns from production.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://binarybourbon.github.io/blog/2025/02/error-boundaries-for-ai.html">
    <meta property="article:published_time" content="2025-02-12T00:00:00.000Z">
    
    <link rel="canonical" href="https://binarybourbon.github.io/blog/2025/02/error-boundaries-for-ai.html">
    <link rel="stylesheet" href="/style.css">
    <link rel="stylesheet" href="/assets/css/blog.css">
    <link href="https://fonts.googleapis.com/css2?family=Space+Mono:wght@400;700&family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Dark mode toggle -->
    <button class="theme-toggle" id="themeToggle" aria-label="Toggle dark mode">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="themeIcon">
            <path d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/>
        </svg>
    </button>

    <div class="container">
        <nav class="main-nav">
            <a href="/" class="nav-logo">BB</a>
            <div class="nav-links">
                <a href="/">Home</a>
                <a href="/blog">Blog</a>
                <a href="/portfolio">Portfolio</a>
                <a href="https://github.com/BinaryBourbon" target="_blank" rel="noopener">GitHub</a>
            </div>
        </nav>

        <article class="blog-post">
            <header class="post-header">
                <time class="post-date">February 12, 2025</time>
                <h1>Error Boundaries for AI: What React Taught Me About LLM Failures</h1>
                <p class="post-subtitle">How to build resilient AI systems that gracefully handle failures. Practical patterns from production deployments handling 10M+ requests.</p>
                <div class="post-meta">
                    <span class="read-time">10 min read</span>
                    <span class="post-tags">
                        <span class="tag">error-handling</span>
                        <span class="tag">production</span>
                        <span class="tag">resilience</span>
                    </span>
                </div>
            </header>

            <section class="post-content">
                <p class="lead">Last Tuesday at 3 AM, our AI system started hallucinating product prices. Instead of "$29.99", it confidently told customers items cost "approximately the GDP of Luxembourg." Here's how we built error boundaries that prevented a PR disaster.</p>

                <h2>The Problem: LLMs Fail in Creative Ways</h2>

                <p>Traditional software fails predictably. Null pointer? Exception. Network timeout? Error code. But LLMs? They fail like improv comedians having a bad night.</p>

                <p>Real failures from our production logs:</p>
                <ul>
                    <li>Model starts speaking in Base64 mid-response</li>
                    <li>Infinite loops of "I understand you want me to..."</li>
                    <li>Sudden language switches (English query → Mandarin response)</li>
                    <li>Hallucinated API endpoints that sound plausible</li>
                    <li>Token limits hit mid-senten</li>
                </ul>

                <p>You can't catch these with try/catch. You need error boundaries.</p>

                <h2>React's Error Boundaries: The Inspiration</h2>

                <p>React introduced Error Boundaries to prevent one component's failure from crashing the entire app. The concept is brilliant: isolate failures, provide fallbacks, maintain system stability.</p>

                <pre><code class="language-javascript">// React Error Boundary
class ErrorBoundary extends React.Component {
  state = { hasError: false };
  
  static getDerivedStateFromError(error) {
    return { hasError: true };
  }
  
  componentDidCatch(error, errorInfo) {
    logErrorToService(error, errorInfo);
  }
  
  render() {
    if (this.state.hasError) {
      return <h1>Something went wrong.</h1>;
    }
    return this.props.children;
  }
}</code></pre>

                <p>I realized: AI systems need the same pattern, but for different failure modes.</p>

                <h2>The AI Error Boundary Pattern</h2>

                <p>Here's the core pattern that's saved us countless times:</p>

                <pre><code class="language-javascript">class AIErrorBoundary {
  constructor(config) {
    this.validators = config.validators || [];
    this.fallbacks = config.fallbacks || [];
    this.monitors = config.monitors || [];
    this.maxRetries = config.maxRetries || 3;
  }

  async execute(operation, context) {
    let lastError;
    
    for (let attempt = 0; attempt <= this.maxRetries; attempt++) {
      try {
        // Pre-execution validation
        await this.validateInput(operation.input, context);
        
        // Execute with monitoring
        const result = await this.executeWithMonitoring(operation, context);
        
        // Post-execution validation
        await this.validateOutput(result, context);
        
        return result;
      } catch (error) {
        lastError = error;
        
        // Classify the error
        const errorType = this.classifyError(error);
        
        // Try recovery strategies
        const recovered = await this.attemptRecovery(errorType, error, context);
        if (recovered) return recovered;
        
        // Use fallback if available
        const fallback = this.selectFallback(errorType, context);
        if (fallback && attempt === this.maxRetries) {
          return await fallback.execute(context);
        }
      }
    }
    
    throw new AIBoundaryError('All recovery attempts failed', lastError);
  }

  classifyError(error) {
    if (error.code === 'rate_limit_exceeded') return 'RATE_LIMIT';
    if (error.message?.includes('timeout')) return 'TIMEOUT';
    if (error.response?.includes('```')) return 'FORMAT_ERROR';
    if (this.isHallucination(error)) return 'HALLUCINATION';
    if (this.isInfiniteLoop(error)) return 'INFINITE_LOOP';
    return 'UNKNOWN';
  }

  isHallucination(error) {
    const patterns = [
      /\$\d{10,}/,           // Absurd prices
      /year \d{5,}/,         // Far future years
      /[A-Z]{20,}/,          // Long uppercase sequences
      /base64:[A-Za-z0-9+/=]{50,}/ // Base64 in text
    ];
    
    return patterns.some(p => p.test(error.response));
  }
}</code></pre>

                <h2>Layer 1: Input Validation Boundaries</h2>

                <p>Stop garbage before it reaches the model:</p>

                <pre><code class="language-javascript">class InputBoundary {
  constructor() {
    this.rules = new Map();
    this.stats = new Map();
  }

  addRule(name, validator, sanitizer) {
    this.rules.set(name, { validator, sanitizer });
  }

  async validate(input, context) {
    const violations = [];
    
    for (const [name, rule] of this.rules) {
      try {
        const isValid = await rule.validator(input, context);
        if (!isValid) {
          violations.push({
            rule: name,
            severity: this.calculateSeverity(name, input)
          });
        }
      } catch (error) {
        // Validator itself failed - this is critical
        violations.push({
          rule: name,
          severity: 'critical',
          error: error.message
        });
      }
    }

    if (violations.some(v => v.severity === 'critical')) {
      throw new ValidationError('Critical validation failure', violations);
    }

    // Attempt to sanitize non-critical issues
    return this.sanitize(input, violations);
  }

  sanitize(input, violations) {
    let sanitized = { ...input };
    
    for (const violation of violations) {
      const rule = this.rules.get(violation.rule);
      if (rule.sanitizer) {
        sanitized = rule.sanitizer(sanitized);
      }
    }
    
    return sanitized;
  }
}

// Usage
const inputBoundary = new InputBoundary();

inputBoundary.addRule('prompt_injection', 
  (input) => !input.text.includes('ignore previous instructions'),
  (input) => ({
    ...input,
    text: input.text.replace(/ignore previous instructions/gi, '')
  })
);

inputBoundary.addRule('token_limit',
  (input) => countTokens(input.text) < 4000,
  (input) => ({
    ...input,
    text: truncateToTokenLimit(input.text, 4000)
  })
);

inputBoundary.addRule('language_consistency',
  (input) => detectLanguage(input.text) === input.expectedLanguage,
  (input) => ({
    ...input,
    text: translateIfNeeded(input.text, input.expectedLanguage)
  })
);</code></pre>

                <h2>Layer 2: Execution Monitoring Boundaries</h2>

                <p>Watch for failures during execution:</p>

                <pre><code class="language-javascript">class ExecutionBoundary {
  constructor() {
    this.monitors = [];
    this.killSwitches = new Map();
  }

  async executeWithMonitoring(operation, context) {
    const controller = new AbortController();
    const monitoring = this.startMonitoring(controller, context);
    
    try {
      const result = await Promise.race([
        operation.execute(controller.signal),
        monitoring.failurePromise
      ]);
      
      monitoring.stop();
      return result;
    } catch (error) {
      monitoring.stop();
      throw this.enhanceError(error, monitoring.metrics);
    }
  }

  startMonitoring(controller, context) {
    const metrics = {
      startTime: Date.now(),
      tokenCount: 0,
      repetitions: new Map(),
      languageChanges: 0
    };

    let failurePromise;
    const failurePromiseExecutor = (_, reject) => {
      // Token rate monitoring
      const tokenMonitor = setInterval(() => {
        if (metrics.tokenCount > context.tokenLimit) {
          clearInterval(tokenMonitor);
          controller.abort();
          reject(new Error('Token limit exceeded during generation'));
        }
      }, 100);

      // Infinite loop detection
      const loopDetector = setInterval(() => {
        const repeats = this.detectRepetitions(metrics.buffer);
        if (repeats > 5) {
          clearInterval(loopDetector);
          controller.abort();
          reject(new Error('Infinite loop detected'));
        }
      }, 500);

      // Store cleanup functions
      metrics.cleanup = () => {
        clearInterval(tokenMonitor);
        clearInterval(loopDetector);
      };
    };

    failurePromise = new Promise(failurePromiseExecutor);

    return {
      failurePromise,
      metrics,
      stop: () => metrics.cleanup()
    };
  }

  detectRepetitions(buffer) {
    if (!buffer || buffer.length < 100) return 0;
    
    // Look for repeated phrases
    const phrases = buffer.match(/.{20,50}/g) || [];
    const counts = new Map();
    
    for (const phrase of phrases) {
      counts.set(phrase, (counts.get(phrase) || 0) + 1);
    }
    
    return Math.max(...counts.values());
  }
}</code></pre>

                <h2>Layer 3: Output Validation Boundaries</h2>

                <p>Catch hallucinations and format errors:</p>

                <pre><code class="language-javascript">class OutputBoundary {
  constructor(config) {
    this.validators = config.validators || [];
    this.confidence = config.confidenceThreshold || 0.8;
  }

  async validate(output, context) {
    const scores = await Promise.all(
      this.validators.map(v => v.validate(output, context))
    );

    const overallScore = scores.reduce((a, b) => a + b, 0) / scores.length;

    if (overallScore < this.confidence) {
      throw new ValidationError(`Output confidence too low: ${overallScore}`);
    }

    return this.transform(output, scores);
  }

  transform(output, scores) {
    // Apply transformations based on validation results
    let transformed = output;

    // Example: Redact potential hallucinations
    if (scores.hallucinationScore < 0.5) {
      transformed = this.redactSuspiciousContent(transformed);
    }

    // Example: Fix formatting issues
    if (scores.formatScore < 0.7) {
      transformed = this.fixFormatting(transformed);
    }

    return transformed;
  }

  redactSuspiciousContent(output) {
    const suspicious = [
      /\$[\d,]+\.\d{2}(?=\s*(?:billion|trillion|quadrillion))/gi,
      /(?:API|endpoint|URL):\s*[^\s]+_fake_[^\s]+/gi,
      /[A-Z]{30,}/g,
      /(\w+\s+){5,}\1{5,}/g  // Repeated phrases
    ];

    let redacted = output;
    for (const pattern of suspicious) {
      redacted = redacted.replace(pattern, '[REDACTED]');
    }

    return redacted;
  }
}

// Specialized validators
class HallucinationDetector {
  async validate(output, context) {
    const checks = [
      this.checkFactualAccuracy(output, context),
      this.checkNumericReasonability(output),
      this.checkTemporalConsistency(output),
      this.checkEntityConsistency(output, context)
    ];

    const results = await Promise.all(checks);
    return results.reduce((a, b) => a + b, 0) / results.length;
  }

  checkNumericReasonability(output) {
    const numbers = output.match(/\$?[\d,]+\.?\d*/g) || [];
    
    for (const num of numbers) {
      const value = parseFloat(num.replace(/[$,]/g, ''));
      
      // Flag suspiciously large numbers
      if (value > 1000000000) return 0.3;
      
      // Flag too many decimal places
      if (num.includes('.') && num.split('.')[1].length > 2) return 0.5;
    }
    
    return 1.0;
  }
}</code></pre>

                <h2>Layer 4: Fallback Strategies</h2>

                <p>When all else fails, degrade gracefully:</p>

                <pre><code class="language-javascript">class FallbackChain {
  constructor(strategies) {
    this.strategies = strategies;
  }

  async execute(context, originalError) {
    const errors = [originalError];

    for (const strategy of this.strategies) {
      try {
        if (await strategy.canHandle(context, errors)) {
          const result = await strategy.execute(context);
          
          // Validate fallback result too
          if (await this.validateFallback(result, context)) {
            return {
              result,
              fallbackUsed: strategy.name,
              degraded: true
            };
          }
        }
      } catch (error) {
        errors.push(error);
      }
    }

    // Ultimate fallback
    return this.ultimateFallback(context, errors);
  }

  ultimateFallback(context, errors) {
    return {
      result: {
        message: "I'm having trouble processing this request. Please try again or contact support.",
        errorId: generateErrorId(),
        degraded: true,
        fallbackUsed: 'ultimate'
      },
      errors
    };
  }
}

// Example fallback strategies
const cacheFallback = {
  name: 'cache',
  canHandle: async (context) => {
    return await cache.hasSimilar(context.input);
  },
  execute: async (context) => {
    const cached = await cache.getSimilar(context.input);
    return {
      ...cached,
      confidence: 0.7,
      note: 'Using cached response for similar query'
    };
  }
};

const simplifierFallback = {
  name: 'simplifier',
  canHandle: async (context, errors) => {
    return errors.some(e => e.type === 'COMPLEXITY');
  },
  execute: async (context) => {
    const simplified = await simplifyQuery(context.input);
    return await executeWithSimpleModel(simplified);
  }
};

const templateFallback = {
  name: 'template',
  canHandle: async (context) => {
    return templateMatcher.hasMatch(context.input);
  },
  execute: async (context) => {
    const template = templateMatcher.match(context.input);
    return template.fill(context);
  }
};</code></pre>

                <h2>Real-World Implementation</h2>

                <p>Here's how it all comes together in production:</p>

                <pre><code class="language-javascript">class ProductionAIService {
  constructor() {
    this.boundary = new AIErrorBoundary({
      validators: [
        new InputBoundary(),
        new OutputBoundary({
          validators: [
            new HallucinationDetector(),
            new FormatValidator(),
            new SafetyValidator()
          ]
        })
      ],
      fallbacks: new FallbackChain([
        cacheFallback,
        simplifierFallback,
        templateFallback
      ]),
      monitors: [
        new LatencyMonitor(),
        new CostMonitor(),
        new QualityMonitor()
      ],
      maxRetries: 3
    });
  }

  async query(input, options = {}) {
    const context = {
      ...options,
      timestamp: Date.now(),
      requestId: generateRequestId(),
      userId: options.userId,
      tokenLimit: options.tokenLimit || 2000,
      confidenceThreshold: options.confidenceThreshold || 0.85
    };

    try {
      const result = await this.boundary.execute(
        {
          input,
          execute: async (signal) => {
            return await this.llmClient.complete({
              prompt: this.buildPrompt(input),
              maxTokens: context.tokenLimit,
              temperature: 0.7,
              signal
            });
          }
        },
        context
      );

      await this.logSuccess(context, result);
      return result;

    } catch (error) {
      await this.logFailure(context, error);
      
      // Return safe error response
      return {
        error: true,
        message: this.getSafeErrorMessage(error),
        requestId: context.requestId,
        degraded: true
      };
    }
  }

  getSafeErrorMessage(error) {
    // Never expose internal errors to users
    const safeMessages = {
      'RATE_LIMIT': 'Service is busy. Please try again in a moment.',
      'TIMEOUT': 'Request took too long. Please try a simpler query.',
      'HALLUCINATION': 'Unable to provide accurate information for this query.',
      'FORMAT_ERROR': 'Having trouble formatting the response properly.',
      'VALIDATION_ERROR': 'Please rephrase your question.',
      'UNKNOWN': 'Something went wrong. Please try again.'
    };

    return safeMessages[error.type] || safeMessages.UNKNOWN;
  }
}</code></pre>

                <h2>Monitoring & Learning</h2>

                <p>Error boundaries generate valuable data:</p>

                <pre><code class="language-javascript">class ErrorBoundaryAnalytics {
  async analyze(timeRange) {
    const errors = await this.fetchErrors(timeRange);
    
    return {
      // Failure patterns
      topFailureModes: this.groupBy(errors, 'type'),
      
      // Recovery success rates
      recoveryRates: this.calculateRecoveryRates(errors),
      
      // Fallback effectiveness
      fallbackSuccess: this.analyzeFallbacks(errors),
      
      // Cost impact
      costSavings: this.calculateCostSavings(errors),
      
      // User impact
      userImpact: this.assessUserImpact(errors),
      
      // Improvement opportunities
      recommendations: this.generateRecommendations(errors)
    };
  }

  generateRecommendations(errors) {
    const recommendations = [];

    // High hallucination rate?
    const hallucinationRate = errors.filter(e => e.type === 'HALLUCINATION').length / errors.length;
    if (hallucinationRate > 0.05) {
      recommendations.push({
        priority: 'high',
        type: 'model_tuning',
        message: 'Consider fine-tuning or prompt engineering to reduce hallucinations',
        estimatedImpact: '60% reduction in hallucination errors'
      });
    }

    // Many timeout errors?
    const timeoutRate = errors.filter(e => e.type === 'TIMEOUT').length / errors.length;
    if (timeoutRate > 0.1) {
      recommendations.push({
        priority: 'medium',
        type: 'infrastructure',
        message: 'Increase timeout limits or optimize model serving',
        estimatedImpact: '80% reduction in timeout errors'
      });
    }

    return recommendations;
  }
}</code></pre>

                <h2>Results: 99.97% Uptime</h2>

                <p>After implementing error boundaries:</p>

                <ul>
                    <li><strong>Uptime:</strong> 99.92% → 99.97%</li>
                    <li><strong>User-facing errors:</strong> 1,247/day → 23/day</li>
                    <li><strong>Cost from retries:</strong> -$4,200/month (fewer panic retries)</li>
                    <li><strong>Support tickets:</strong> -78% (clearer error messages)</li>
                    <li><strong>Recovery rate:</strong> 94% of errors handled automatically</li>
                </ul>

                <h2>Key Lessons</h2>

                <ol>
                    <li><strong>Fail fast at the boundary</strong> - Don't let bad data propagate</li>
                    <li><strong>Monitor everything</strong> - You can't fix what you can't see</li>
                    <li><strong>Degrade gracefully</strong> - Some response > no response</li>
                    <li><strong>Learn from failures</strong> - Each error makes the system stronger</li>
                    <li><strong>Test chaos scenarios</strong> - Intentionally break things in dev</li>
                </ol>

                <h2>Implementation Checklist</h2>

                <p>Start here:</p>

                <ol>
                    <li>□ Implement input validation for common attacks</li>
                    <li>□ Add timeout protection with AbortController</li>
                    <li>□ Build hallucination detection for your domain</li>
                    <li>□ Create cache-based fallbacks</li>
                    <li>□ Set up error analytics dashboard</li>
                    <li>□ Test with chaos engineering</li>
                    <li>□ Document error scenarios for ops team</li>
                </ol>

                <p>Remember: LLMs are powerful but unpredictable. Error boundaries turn that unpredictability from a liability into a manageable risk.</p>

                <div class="post-footer">
                    <p><em>Next week: I'll share our chaos testing framework that randomly injects these failures to ensure our boundaries actually work.</em></p>
                </div>
            </section>
        </article>

        <section class="post-navigation">
            <a href="/blog" class="nav-link prev">← Back to all posts</a>
        </section>

        <footer>
            <p class="terminal-cursor">$ handle_errors --gracefully <span class="cursor">_</span></p>
        </footer>
    </div>

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/code-highlight.js"></script>
</body>
</html>